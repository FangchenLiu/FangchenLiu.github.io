<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>LIU, Fangchen</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <link rel="stylesheet" href="bootstrap.css" media="screen">
    <link rel="stylesheet" href="bootstrap.min.css">
    <script>
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-23019901-1']);
        _gaq.push(['_setDomainName', "bootswatch.com"]);
        _gaq.push(['_setAllowLinker', true]);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <style type="text/css">
        .page-footer {
            border-top: 1px solid #dddddd;
        }

        .author {
            bold;
        }
    </style>
</head>
<body>
<div class="container">
    <div id="banner" class="page-header">
        <div class="row">
            <div class="col-lg-8 col-md-7 col-sm-6">
                <h3>LIU, Fangchen (Catherine)</h3>
                <p class="lead">Senior Student<br>Computer Science Department,
                    Peking University</p>
                <span style="font-size:16px">
                No.5 Yiheyuan Road<br>
                Haidian, Beijing, China<br>
            </span>
                <span style="font-size:14px"><strong>Email:</strong> <a
                        href="mailto:liufangchen{a}pku.edu.cn">liufangchen {at} pku.edu.cn</a></span><br>
                <a href="files/CV_Fangchen_Liu.pdf">[My CV]</a>
            </div>
            <div class="col-lg-4 col-md-5 col-sm-6">
                <div class="sponsor">
                    <img alt="Picture of Fangchen Liu" height="290px"
                         src="./images/lfc.jpeg" width="400px">
                </div>
            </div>
        </div>
    </div>
    <hr>
    <div class="row">
        <div class="col-lg-10">
            <h3>Bio</h3>
            <p style="font-size:14px;font-family:helvetica">
            I am now a senior student in <a href="http://www.pku.edu.cn">Peking
            University</a>, majoring in Computer Science. In 2016, I joined
            the Institute of Digital Media at Peking University as a
            research assistant, and I am currently supervised by <a
                href="http://www.idm.pku.edu.cn/staff/wangyizhou/">Prof.
            Yizhou Wang</a> with honor.
            Piror to that, I was a researcher at SenseTime Group Limited,
            which is a leading artificial intelligence startup in China,
            working on face recognition with Dr. Yi Sun.
            I worked at <a href="http://bair.berkeley.edu/">Berkeley
            Artificial Intelligence Research</a> as a visiting researcher,
            under the guidance of <a
                href="https://people.eecs.berkeley.edu/~trevor">Prof. Trevor
            Darrell</a> and <a href="http://www.yf.io">Dr. Fisher Yu</a>. We
            worked closely on autonomous driving and 3D reconstruction.
            Now, I also serve as a researcher at Microsoft Research Asia,
            Visual Computing Group, supervised by <a
                href="https://sites.google.com/site/jimxinbo/">Dr. Bo
            Xin</a>. Our work focuses on video game playing, which bridges
            computer vision to the fields of reinforcement learning and
            multi-agent systems.</p>
            <p style="font-size:14px;font-family:helvetica">
                My research interests mainly lie in computer vision, machine
                learning, multi-agent systems and their applications. To be
                specific, I am interested in exploring topics that can expand
                the horizons of the vision community, such as video game
                playing, multimodal computing and self-driving. Besides, I hope
                to apply my knowledge of reinforcement learning and multi-agent
                systems to robotics, and further investigate topics of
                human-robot interaction and multi-agent collaboration.</p>
        </div>
    </div>
    <br>
    <div class="row">
        <div class="col-lg-12" style="font-size:14px;font-family:helvetica">
            <h3>Education</h3>
            <div class="media">
                <span class="pull-left"><img src="./images/peking.png"
                                             width="96px" height="96px"/></span>
                <div class="media-body">
                    <p>Department of Computer Science,
                        <i><b>Peking University
                            University</b></i></p>
                    <span style="font-weight:bold">Sep. 2014 - June 2018
                        (Expected)</span>
                    <p>Bachelor of Science</p>
                </div>
            </div>
            <div class="media">
                <span class="pull-left"><img src="./images/berkeley.png"
                                             width="96px" height="96px"/></span>
                <div class="media-body">
                    <p>Electrical Engineering and Computer
                        Science,
                        <i><b>University of California, Berkeley</b></i></p>
                    <span style="font-weight: bold">June 2017 - Sep
                        2017</span>
                    <p>Visiting Researcher</p>
                </div>
            </div>
        </div>
    </div>
    <br>
    <div class="row">
        <div class="col-lg-12">
            <h3 id="type">Publications</h3>
            <span style="font-size:14px;font-family:helvetica"><li><b><u>F.
            Liu</u>, X. Kong, B. Xin, Y. Wang</b>.<br>
                Anchored A3C: Transferring Computer Vision Wisdoms to Video Game Playing.<br>
                <i>In Submission to CVPR</i>, 2018.<br></span>
            <span style="font-size:14px;font-family:helvetica"><li><b>F. Yu, W.
            Xian, <u>F. Liu</u>, M. Liao, V. Madhavan, T. Darrell</b>.<br>
                A Driving Video Database with Scalable Annotation Tooling.<br>
                <i>In Submission to CVPR</i>, 2018.<br></span>
            <span style="font-size:14px;font-family:helvetica"><li><b>X. Kong,
            <u>F. Liu</u>*, B. Xin*, Y. Wang</b>.<br>
                <a href="https://drive.google.com/file/d/1Yfv5t3JUMMl3HOeVCNrnHAvRlStNWs4e/view">Effective Master-Slave Communication On A Multi-Agent Deep Reinforcement Learning System.</a><br>
                <i>Accepted to Hierachical Reinforcement Learning Workshop at NIPS</i>, 2017.<br></span>
            <span style="font-size:14px;font-family:helvetica"><li><b>X. Kong,
            <u>F. Liu</u>, B. Xin, Y. Wang</b>.<br>
                <a href="https://openreview.net/pdf?id=B1KFAGWAZ">Revisiting the Master-slave Architecture in Multi-agent Deep Reinforcement Learning.</a><br>
                <i>In Submission to ICLR</i>, 2018.<br></span>
        </div>
    </div>
    <div class="row">
        <div class="col-lg-12">
            <p>Since our CVPR 2018 Submissions are currently not available, if
                you want the full PDF, please contact me.</p>
        </div>
    </div>
    <br>
    <div class="row">
        <div class="col-lg-6" style="font-size:14px;font-family:helvetica">
            <h3>Research Projects</h3>
            <div class="media">
                <span class="pull-left"><br /><a href="images/star.png"
                                                 class="image"><img
                        src="images/star.png" width="96px" alt="" /></a></span>
                <div class="media-body">
                    <p><b>Learning to Select in <i>StarCraft II</i> Using A3C
                        Agent with Multi-Scale Anchors</b>, In submission to
                        CVPR 2018</p>
                    <p>Fangchen Liu, Xiangyu Kong, Bo Xin, Yizhou Wang,</p>
                    <p>Sep. 2017 - Nov. 2017,
                        <i><b>Microsoft Research Asia</b></i>,
                    </p>
                    <p>We proposed an A3C agent to learn proper grouping
                        policies with the capacities of both allocating armies
                        and fighting against enemies. Inspired by some
                        one-stage state-of-the-art detection methods, we
                        developed multi-scale anchors to facilitate the
                        selection process, which requires drawing a bounding
                        box on the screen. Our model achieved much
                        better performance when tested on StarCraft II
                        mini-games.</p>
                </div>
            </div>
            <div class="media">
                <span class="pull-left"><br /><a href="images/dataset.png"
                                                 class="image"><img
                        src="images/dataset.png" width="96px" alt="" /></a></span>
                <div class="media-body">
                    <p><b>Large-Scale Driving Dataset with a Scalable Annotation
                        System</b>, In submission to CVPR 2018</p>
                    <p>Fisher Yu, Wenqi Xian, Fangchen Liu, Mike Liao,
                        Vashisht Madhavan, Trevor Darrell,</p>
                    <p>June 2017 - Sep. 2017,
                        <i><b>University of California, Berkeley</b></i>,
                    </p>
                    <p>We implemented a scalable annotation system that can provide a
                        comprehensive set of image labels for large-scale driving
                        datasets and minimized its cost of time by interactive
                        design and innovative features,
                        and then demonstrated that object detection and
                        segmentation models trained on our dataset are much
                        unlikely to be surprised by new driving conditions.</p>
                </div>
            </div>
            <div class="media">
                <span class="pull-left"><br /><a href="images/marl.png"
                                                 class="image"><img
                        src="images/marl.png" width="96px" alt="" /></a></span>
                <div class="media-body">
                    <p><b>Hierarchical Communication and Collaboration in
                        Multi-Agent Reinforcement Learning</b>, Accepted by
                        Hierarchical RL Workshop in NIPS 2017, In submission
                        to ICLR 2018
                    </p>
                    <p>Xiangyu Kong, Bo Xin*, Fangchen Liu*, Yizhou Wang,</p>
                    <p>June 2017 - Sep. 2017,
                        <i><b>Peking University</b></i>,
                    </p>
                    <p>We proposed the master-slave architecture to combine
                        the centralized perspective (the master) with the
                        decentralized ones (the slaves), which is proved to
                        be an effective communication mechanism which
                        facilitate the interactive reinforcement learning
                        process. The master agent aggregates messages uploaded
                        from the slaves and generates unique message to each
                        slave, while each slave incorporates both the
                        master's instruction and its own decisions, and take
                        actions to fulfill the goal. Our model achieved much
                        better performance when tested on StarCraft
                        environment and traffic junction task.
                    </p>
                </div>
            </div>
        </div>
    </div>
<br>
    <div class="row">
        <div class="col-lg-12" style="font-size:14px;font-family:helvetica">
            <h3>Work Experience</h3>
            <li><strong><a
                    href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft
                Research Asia
            </a></strong>
                <br> <b>Research Intern, Visual Computing Group</b>
                <br> Sep. 2017 - Present, Beijing, China
                <br> Worked on video game playing which bridges vision to
                reinforcement learning and multi-agent systems. Our
                work was submitted to CVPR 2018, wherein I served as
                the first author.</br>
            </li>
            <li><strong><a href="https://www.sensetime.com/">SenseTime Group
                Limited</a></strong>
                <br> <b>Research Intern, Face Detection and Recognition
                    Group
                </b>
                <br> Sep. 2016 - Mar. 2017, Beijing, China
                <br> Worked on Face Set Recognition and Memory Networks.
                Some results was integrated into the company's deep
                learning framework and products. </br> </li>
        </div>
    </div>
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                    (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-68395399-1', 'auto');
        ga('send', 'pageview');
    </script>
    <div class="row">
        <div class="col-lg-12">
            <script type="text/javascript"
                    src="//rf.revolvermaps.com/0/0/6.js?i=5oc3w2kbghi&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80"
                    async="async"></script>
        </div>
    </div>
</div>
</body>
</html>

